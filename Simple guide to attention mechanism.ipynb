{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c04e347",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#What-is-attention-in-ML?\" data-toc-modified-id=\"What-is-attention-in-ML?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>What is attention in ML?</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Attention-via-NumPy-and-SciPy\" data-toc-modified-id=\"Attention-via-NumPy-and-SciPy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Attention via <code>NumPy</code> and <code>SciPy</code></a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f56c21",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57169d30",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "**What?** Attention\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60bb4d",
   "metadata": {},
   "source": [
    "# What is attention in ML?\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff814e2d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- An attention-based system is thought to consist of three components:\n",
    "\n",
    "    - A process that “reads” raw data (such as source words in a source sentence), and converts them into **distributed representations**, with one feature vector associated with each word position. \n",
    "\n",
    "    - A list of feature vectors storing the output of the reader. This can be understood as a “memory” containing a sequence of facts, which can be retrieved later, not necessarily in the same order, **without having to visit all of them**.\n",
    "\n",
    "    - A process that “exploits” the content of the memory to sequentially perform a task, at each time step having the **ability put attention** on the content of one memory element (or a few, with a different weight).\n",
    "\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecb1d3",
   "metadata": {},
   "source": [
    "# Imports\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce2e599d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:12:55.458921Z",
     "start_time": "2022-09-01T06:12:55.363919Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cc1f2",
   "metadata": {},
   "source": [
    "# Attention via `NumPy` and `SciPy`\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f94d2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Let’s start by first defining the **word embeddings** of the four different words for which we will be calculating the attention. \n",
    "    \n",
    "- In reality, these word embeddings would have been generated by an **encoder**, however for this particular example we shall be defining them manually. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0511c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:07:24.455768Z",
     "start_time": "2022-09-01T06:07:24.452678Z"
    }
   },
   "outputs": [],
   "source": [
    "# encoder representations of four different words\n",
    "word_1 = np.array([1, 0, 0])\n",
    "word_2 = np.array([0, 1, 0])\n",
    "word_3 = np.array([1, 1, 0])\n",
    "word_4 = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b411c27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Let's now generate the weight matrices, which we will eventually be multiplying to the word embeddings to generate the queries, keys and values. \n",
    "\n",
    "- Here, we shall be generating these weight matrices randomly, however in actual practice these would **have been learned during training**. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5841621c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:08:09.748234Z",
     "start_time": "2022-09-01T06:08:09.744822Z"
    }
   },
   "outputs": [],
   "source": [
    "...\n",
    "# generating the weight matrices\n",
    "np.random.seed(42) # to allow us to reproduce the same attention values\n",
    "W_Q = np.random.randint(3, size=(3, 3))\n",
    "W_K = np.random.randint(3, size=(3, 3))\n",
    "W_V = np.random.randint(3, size=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a338a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- The query, key and value vectors for each word are generated by multiplying each word embedding by each of the weight matrices. \n",
    "    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1853bab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:10:38.926854Z",
     "start_time": "2022-09-01T06:10:38.922231Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating the queries, keys and values\n",
    "query_1 = word_1 @ W_Q\n",
    "key_1 = word_1 @ W_K\n",
    "value_1 = word_1 @ W_V\n",
    " \n",
    "query_2 = word_2 @ W_Q\n",
    "key_2 = word_2 @ W_K\n",
    "value_2 = word_2 @ W_V\n",
    " \n",
    "query_3 = word_3 @ W_Q\n",
    "key_3 = word_3 @ W_K\n",
    "value_3 = word_3 @ W_V\n",
    " \n",
    "query_4 = word_4 @ W_Q\n",
    "key_4 = word_4 @ W_K\n",
    "value_4 = word_4 @ W_V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc367cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Considering only the first word for the time being, the next step scores its query vector against all of the key vectors using a dot product operation. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d0544c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:11:23.678487Z",
     "start_time": "2022-09-01T06:11:23.675658Z"
    }
   },
   "outputs": [],
   "source": [
    "# scoring the first query vector against all key vectors\n",
    "scores = np.array([np.dot(query_1, key_1), np.dot(query_1, key_2),\n",
    "               np.dot(query_1, key_3), np.dot(query_1, key_4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7487375",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- The score values are subsequently passed through a softmax operation to generate the weights. \n",
    "    \n",
    "- Before doing so, it is **common practice** to divide the score values by the square root of the dimensionality of the key vectors (in this case, three), to keep the gradients stable. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b67c2ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:12:58.899806Z",
     "start_time": "2022-09-01T06:12:58.897143Z"
    }
   },
   "outputs": [],
   "source": [
    "# computing the weights by a softmax operation\n",
    "weights = softmax(scores / key_1.shape[0] ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8e8f3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font color=black>\n",
    "\n",
    "- Finally, the attention output is calculated by a weighted sum of all four value vectors. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "befef395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-01T06:13:34.787461Z",
     "start_time": "2022-09-01T06:13:34.783936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98522025 1.74174051 0.75652026]\n"
     ]
    }
   ],
   "source": [
    "# computing the attention by a weighted sum of the value vectors\n",
    "attention = (weights[0] * value_1) + (weights[1] * value_2) + \\\n",
    "    (weights[2] * value_3) + (weights[3] * value_4)\n",
    "\n",
    "print(attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80aefa",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style = \"border:2px solid black\" ></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b1568",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font color=black>\n",
    "\n",
    "- https://machinelearningmastery.com/what-is-attention/\n",
    "- https://machinelearningmastery.com/the-attention-mechanism-from-scratch/\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccd26a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
