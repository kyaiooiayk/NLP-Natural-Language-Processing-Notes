{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Text Classification with Naive Bayes, Logistic Regression, SVM\n",
    "\n",
    "Reference: https://github.com/practical-nlp/practical-nlp/blob/master/Ch4/01_OnePipeline_ManyClassifiers.ipynb\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #to work with csv files\n",
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import string\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Getting rid of the warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loda dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We will be using a dataset called \"Economic news article tone and relevance\" from Figure-Eight which consists of \n",
    "approximately 8000 news articles, which were tagged as relevant or not relevant to the US Economy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "LbED8Q185xWu",
    "outputId": "6bc758e1-c542-4309-a8b7-f9ae406bde7d"
   },
   "outputs": [],
   "source": [
    "our_data = pd.read_csv(\"./Full-Economic-News-DFE-839861.csv\" , encoding = \"ISO-8859-1\" )\n",
    "\n",
    "display(our_data.shape) #Number of rows (instances) and columns in the dataset\n",
    "our_data[\"relevance\"].value_counts()/our_data.shape[0] #Class distribution in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "vCED1t7F5xW9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There is an imbalance in the data with **not relevant** being 82% in the dataset. That is, most of the articles \n",
    "are not relevant to US Economy, which makes sense in a real-world scenario, as news articles discuss various topics. \n",
    "We should keep this class imbalance mind when interpreting the classifier performance later. Let us first convert the\n",
    "class labels into binary outcome variables for convenience. 1 for Yes (relevant), and 0 for No (not relevant), and \n",
    "ignore \"Not sure\". \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BYW_S3585xXF",
    "outputId": "988c2d6e-9826-4651-d6b6-2464d2479062"
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "our_data = our_data[our_data.relevance != \"not sure\"]\n",
    "our_data.shape\n",
    "our_data['relevance'] = our_data.relevance.map({'yes':1, 'no':0}) #relevant is 1, not-relevant is 0. \n",
    "our_data = our_data[[\"text\",\"relevance\"]] #Let us take only the two columns we need.\n",
    "our_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOKz8xQr5xXJ"
   },
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "yhC5TZuL5xXK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Typical steps involve tokenization, lower casing, removing, stop words, punctuation markers etc, and vectorization. \n",
    "Other processes such as stemming/lemmatization can also be performed. Here, we are performing the following steps: \n",
    "removing br tags, punctuation, numbers, and stopwords. While we are using sklearn's list of stopwords, there are \n",
    "several other stop word lists (e.g., from NLTK) or sometimes, custom stopword lists are needed depending on the task. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MZSHdHZ5xXL"
   },
   "outputs": [],
   "source": [
    "stopwords = stop_words.ENGLISH_STOP_WORDS\n",
    "def clean(doc): #doc is a string of text\n",
    "    doc = doc.replace(\"</br>\", \" \") #This text contains a lot of <br/> tags.\n",
    "    doc = \"\".join([char for char in doc if char not in string.punctuation and not char.isdigit()])\n",
    "    doc = \" \".join([token for token in doc.split() if token not in stopwords])\n",
    "    #remove punctuation and numbers\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "3CfVm42o5xXS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we are ready for the modelling. We are going to use algorithms from sklearn package. We will go through the \n",
    "following steps:\n",
    "\n",
    "1 Split the data into training and test sets (75% train, 25% test)    \n",
    "2 Extract features from the training data using CountVectorizer, which is a bag of words feature  implementation. \n",
    "  We will use the pre-processing function above in conjunction with Count Vectorizer  \n",
    "3 Transform the test data into the same feature vector as the training data.  \n",
    "4 Train the classifier  \n",
    "5 Evaluate the classifier \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "GimJJHhg5xYl",
    "outputId": "e8d8dbea-9a85-4ca9-c41a-6cdd092b68df"
   },
   "outputs": [],
   "source": [
    "#Step 1: train-test split\n",
    "X = our_data.text #the column text contains textual data to extract features from\n",
    "y = our_data.relevance #this is the column we are learning to predict. \n",
    "print(X.shape, y.shape)\n",
    "# split X and y into training and testing sets. By default, it splits 75% training and 25% test\n",
    "#random_state=1 for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gsUyIBUD5xZI",
    "outputId": "f704fb2b-d1f1-4c3a-d220-f05ee1384a61"
   },
   "outputs": [],
   "source": [
    "#Step 2-3: Preprocess and Vectorize train and test data\n",
    "vect = CountVectorizer(preprocessor=clean) #instantiate a vectoriezer\n",
    "X_train_dtm = vect.fit_transform(X_train)#use it to extract features from training data\n",
    "#transform testing data (using training data's features)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "#i.e., the dimension of our feature vector is 49753!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=15)\n",
    "    plt.xlabel('Predicted label',fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "nDLwA4CL5xZq",
    "outputId": "d1fea858-5e17-4d3e-9450-ae5702114261"
   },
   "outputs": [],
   "source": [
    "#Step 3: Train the classifier and predict for test data\n",
    "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes model\n",
    "%time nb.fit(X_train_dtm, y_train)#train the model(timing it with an IPython \"magic command\")\n",
    "y_pred_class = nb.predict(X_test_dtm)#make class predictions for X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "colab_type": "code",
    "id": "LiCHjvc75xZ3",
    "outputId": "5308276c-78cd-48c3-bf5c-1f6eb5321152"
   },
   "outputs": [],
   "source": [
    "#Step 4: Evaluate the classifier using various measures\n",
    "\n",
    "# Function to plot confusion matrix. \n",
    "# Ref:http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "  \n",
    "    \n",
    "#Print accuracy:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "    \n",
    "# print the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with all features')\n",
    "\n",
    "# calculate AUC: Area under the curve(AUC) gives idea about the model efficiency:\n",
    "#Further information: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "print(\"ROC_AOC_Score: \", roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "ga5-KhYN5xaD"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At this point, we can notice that the classifier is doing poorly with identifying relevant articles, while it is\n",
    "doing well with non-relevant ones. Our large feature vector could be creating a lot of noise in the form of very\n",
    "rarely occurring features that are not useful for learning. Let us change the count vectorizer to take a certain\n",
    "number of features as maximum. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "ylOI4OsD5xaE",
    "outputId": "1db10ac7-a249-474a-b9f7-7d4e57af93c5"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(preprocessor=clean, max_features=5000) #Step-1\n",
    "X_train_dtm = vect.fit_transform(X_train)#combined step 2 and 3\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB() \n",
    "# Train the model(timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)\n",
    "# Make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred_class))\n",
    "# Print the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with max 5000 features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "2JzJ6k7g5xaL"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Clearly, the performance on relevance classification got better even though the overall accuracy fell by 10%. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let us try another classification algorithm and see if the performance changes. For this experiment, we have \n",
    "considered logistic regression, with class_weight attribute as \"balanced\", to address the problem of class \n",
    "imbalance in this dataset. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "colab_type": "code",
    "id": "0v7pM9hB5xbA",
    "outputId": "efcfc795-ad19-44fe-e557-67dc8301363c"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight=\"balanced\") #instantiate a logistic regression model\n",
    "logreg.fit(X_train_dtm, y_train) #fit the model with training data\n",
    "\n",
    "#Make predictions on test data\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "#calculate evaluation measures:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
    "print(\"AUC: \", roc_auc_score(y_test, y_pred_prob))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC - Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "6v1evQyy5xbe"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let us wrap this notebook by trying with one more classifier, but reducing the feature vector size to 1000.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "XJLKusAQ5xbf",
    "outputId": "2d8342ee-cf45-45d5-8a08-cf996b6fbdd8"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(preprocessor=clean, max_features=1000) #Step-1\n",
    "X_train_dtm = vect.fit_transform(X_train)#combined step 2 and 3\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "classifier = LinearSVC(class_weight='balanced') #instantiate a logistic regression model\n",
    "classifier.fit(X_train_dtm, y_train) #fit the model with training data\n",
    "\n",
    "#Make predictions on test data\n",
    "y_pred_class = classifier.predict(X_test_dtm)\n",
    "\n",
    "#calculate evaluation measures:\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_class))\n",
    "print(\"AUC: \", roc_auc_score(y_test, y_pred_prob))\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_class)\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['Not Relevant','Relevant'],normalize=True,\n",
    "                      title='Confusion matrix with normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "Fd_-M70F5xbl"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So, how do we choose whats the best? \n",
    "\n",
    " - If we look at overall accuracy alone, we should be choosing the very first classifier in this notebook. However, \n",
    "   that is also doing poorly with identifying \"relevant\" articles. \n",
    " - If we choose purely based on how good it is doing with \"relevant\" category, we should choose the second one we\n",
    "   built. \n",
    "\n",
    "So, what to choose as the best among these depends on what we are looking for in our usecase! \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Notebook_1.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
