{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** Pre-trained Word2Vec embedding model\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "import gzip\n",
    "import shutil\n",
    "#This module ignores the various types of warnings generated\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "#This module helps in retrieving information on running processes and system resource utilization\n",
    "import psutil \n",
    "from psutil import virtual_memory\n",
    "import time \n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Let us take an example of a pre-trained word2vec model, and how we can use it to look for most similar words. \n",
    "- We will use the Google News vectors embeddings. https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
    "- **ATTENTION!** the file sizr is: 1.65GB it will take a while to download. The decompressed size is over 3GB\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:45:44.132578Z",
     "start_time": "2021-04-03T11:45:44.115562Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "FTpzLd6dvB6Q",
    "outputId": "525dee74-062c-42d6-ce35-27e8cb072101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model at GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "gn_vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "if not os.path.exists(\"GoogleNews-vectors-negative300.bin\"):\n",
    "    if not os.path.exists(\"./GoogleNews-vectors-negative300.bin\"):\n",
    "        # Downloading the reqired model\n",
    "        if not os.path.exists(\"./GoogleNews-vectors-negative300.bin.gz\"):\n",
    "            if not os.path.exists(\"GoogleNews-vectors-negative300.bin.gz\"):\n",
    "                wget.download(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\")\n",
    "            gn_vec_zip_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "        else:\n",
    "            gn_vec_zip_path = \"./GoogleNews-vectors-negative300.bin.gz\"\n",
    "        # Extracting the required model\n",
    "        with gzip.open(gn_vec_zip_path, 'rb') as f_in:\n",
    "            with open(gn_vec_path, 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    else:\n",
    "        gn_vec_path = \"./\" + gn_vec_path\n",
    "\n",
    "print(f\"Model at {gn_vec_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:45:54.417319Z",
     "start_time": "2021-04-03T11:45:54.388099Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ZBsTuJ5FwAFm"
   },
   "outputs": [],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "mem = virtual_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:20.532122Z",
     "start_time": "2021-04-03T11:46:04.765309Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "aodBmqZToPnY",
    "outputId": "5202f6d1-df50-4d78-91e2-9e05558d6cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used in GB before Loading the Model: 1.73\n",
      "----------\n",
      "36.63 seconds taken to load\n",
      "----------\n",
      "Finished loading Word2Vec\n",
      "----------\n",
      "Memory used in GB after Loading the Model: 1.76\n",
      "----------\n",
      "Percentage increase in memory usage: 101.87% \n",
      "----------\n",
      "Numver of words in vocablulary [Mil]: 3.0\n"
     ]
    }
   ],
   "source": [
    "pretrainedpath = gn_vec_path\n",
    "\n",
    "# Load W2V model. This will take some time, but it is a one time effort! \n",
    "pre = process.memory_info().rss\n",
    "# Check memory usage before loading the model\n",
    "print(\"Memory used in GB before Loading the Model: %0.2f\"%float(pre/(10**9))) \n",
    "print('-'*10)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time() \n",
    "# Toal memory available\n",
    "ttl = mem.total \n",
    "\n",
    "# Load the model\n",
    "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True) \n",
    "# Calculate the total time elapsed since starting the timer\n",
    "print(\"%0.2f seconds taken to load\"%float(time.time() - start_time)) \n",
    "print('-'*10)\n",
    "\n",
    "print('Finished loading Word2Vec')\n",
    "print('-'*10)\n",
    "\n",
    "post = process.memory_info().rss\n",
    "# Calculate the memory used after loading the model\n",
    "print(\"Memory used in GB after Loading the Model: {:.2f}\".format(float(post/(10**9)))) \n",
    "print('-'*10)\n",
    "\n",
    "# Percentage increase in memory after loading the model\n",
    "print(\"Percentage increase in memory usage: {:.2f}% \".format(float((post/pre)*100))) \n",
    "print('-'*10)\n",
    "\n",
    "# Number of words in the vocabulary. \n",
    "print(\"Numver of words in vocablulary [Mil]: \" + str(len(w2v_model.key_to_index)/1.e6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How many things can we do?\n",
    "we can inspect the methods with dir\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_load_specials',\n",
       " '_log_evaluate_word_analogies',\n",
       " '_save_specials',\n",
       " '_smart_save',\n",
       " '_upconvert_old_d2vkv',\n",
       " '_upconvert_old_vocab',\n",
       " 'add_lifecycle_event',\n",
       " 'add_vector',\n",
       " 'add_vectors',\n",
       " 'allocate_vecattrs',\n",
       " 'closer_than',\n",
       " 'cosine_similarities',\n",
       " 'distance',\n",
       " 'distances',\n",
       " 'doesnt_match',\n",
       " 'evaluate_word_analogies',\n",
       " 'evaluate_word_pairs',\n",
       " 'expandos',\n",
       " 'fill_norms',\n",
       " 'get_index',\n",
       " 'get_normed_vectors',\n",
       " 'get_vecattr',\n",
       " 'get_vector',\n",
       " 'has_index_for',\n",
       " 'index2entity',\n",
       " 'index2word',\n",
       " 'index_to_key',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'key_to_index',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'log_evaluate_word_pairs',\n",
       " 'mapfile_path',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'most_similar_to_given',\n",
       " 'n_similarity',\n",
       " 'next_index',\n",
       " 'norms',\n",
       " 'rank',\n",
       " 'rank_by_centrality',\n",
       " 'relative_cosine_similarity',\n",
       " 'resize_vectors',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'set_vecattr',\n",
       " 'similar_by_key',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'similarity_unseen_docs',\n",
       " 'sort_by_descending_frequency',\n",
       " 'unit_normalize_all',\n",
       " 'vector_size',\n",
       " 'vectors',\n",
       " 'vectors_norm',\n",
       " 'vocab',\n",
       " 'wmdistance',\n",
       " 'word_vec',\n",
       " 'words_closer_than']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:29.336184Z",
     "start_time": "2021-04-03T11:46:26.529524Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "ZhJ_488PoPnr",
    "outputId": "a0a041db-04e6-4d27-e9a1-2e3f404282f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gorgeous', 0.8353005051612854),\n",
       " ('lovely', 0.8106936812400818),\n",
       " ('stunningly_beautiful', 0.7329413294792175),\n",
       " ('breathtakingly_beautiful', 0.7231340408325195),\n",
       " ('wonderful', 0.6854086518287659),\n",
       " ('fabulous', 0.6700063943862915),\n",
       " ('loveliest', 0.6612576246261597),\n",
       " ('prettiest', 0.6595001816749573),\n",
       " ('beatiful', 0.6593326330184937),\n",
       " ('magnificent', 0.6591402888298035)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us examine the model by knowing what the most similar words are, for a given word!\n",
    "w2v_model.most_similar('beautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:29.509126Z",
     "start_time": "2021-04-03T11:46:29.337187Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "G1Or5oG5oPn1",
    "outputId": "a7a40eb3-9555-4c79-b201-7b8429b947a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('athens', 0.6001025438308716),\n",
       " ('albert', 0.5729556083679199),\n",
       " ('holmes', 0.5693243145942688),\n",
       " ('donnie', 0.5690680146217346),\n",
       " ('italy', 0.5673536658287048),\n",
       " ('toni', 0.5666349530220032),\n",
       " ('spain', 0.566185474395752),\n",
       " ('jh', 0.5661598443984985),\n",
       " ('pablo', 0.563156008720398),\n",
       " ('malta', 0.5620370507240295)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us try with another word! \n",
    "w2v_model.most_similar('rome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:46:30.275722Z",
     "start_time": "2021-04-03T11:46:30.266713Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rtQiYOR9oPn_",
    "outputId": "e804b11f-e72e-4566-963c-786e3e6e580f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the vector representation for a word? \n",
    "w2v_model['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I am looking for a word that is not in this vocabulary?\n",
    "w2v_model['practicalnlp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Two things to note while using pre-trained models: \n",
    "- [1] Tokens/Words are always lowercased. If a word is not in the vocabulary,   the model throws an exception.\n",
    "- [2] So, it is always a good idea to encapsulate those statements in try/except blocks.\n",
    "\n",
""   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the embedding representation for full text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We have seen how to get embedding vectors for single words. \n",
    "- How do we use them to get such a representation for a full text? \n",
    "- A simple way is to just sum or average the embeddings for individual words. \n",
    "- Let us see a small example using another NLP library Spacy\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:48:08.393199Z",
     "start_time": "2021-04-03T11:47:59.993770Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "uFLuSb9ZoPoc",
    "outputId": "35fe37df-f1bd-4c64-c8ad-0455980966ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 591 ms, sys: 51.3 ms, total: 642 ms\n",
      "Wall time: 673 ms\n",
      "[ 1.1530104   0.04257578 -0.12662673 -0.08265086  0.02096112 -0.32236233\n",
      " -0.6240498   0.02519732  0.16935535 -0.7434208   0.27868682 -0.20403433\n",
      " -0.26521063  0.15699737 -0.288515    0.3498006   0.06954589 -0.04919723\n",
      "  0.29010016 -0.19193202 -0.03356849 -0.18861568  0.48819193 -0.10287628\n",
      " -0.27089745 -0.35096675  0.12004175 -0.42992252  0.02619261  0.30020046\n",
      " -0.08323112 -0.22649841  0.38065207 -0.7358086   0.31856763 -0.13183843\n",
      "  0.11280444 -0.16284898  0.13759     0.5194619  -0.49620238  0.22728035\n",
      " -0.19244835  0.1665419  -0.3557002   0.00745243 -0.0097326   0.33902416\n",
      " -0.07566185 -0.2623116   0.38962117 -0.2693131  -0.437186   -0.11987744\n",
      "  0.8256197  -0.05397683  0.40647787  0.23175475  0.14332609  0.20003267\n",
      " -0.62319547 -0.277183   -0.41782817  0.26579994  0.7164182  -0.34532383\n",
      " -0.24082482  0.00639551  0.76979893 -0.40577835  0.475596   -0.10088948\n",
      "  0.09429872 -0.36900702 -0.45953855 -0.06675088  0.08103955 -0.48012877\n",
      "  0.2010462  -0.05818932  0.19529411  0.22707982  0.00196797 -0.06776553\n",
      " -0.01973389 -0.00586809 -0.13960361 -0.45236078 -0.18677695 -0.4244687\n",
      " -0.22704044  0.07753913  0.19231229  0.9452387   0.06845071 -0.44694486]\n"
     ]
    }
   ],
   "source": [
    "%time nlp = spacy.load('en_core_web_sm')\n",
    "# process a sentence using the model\n",
    "mydoc = nlp(\"Canada is a large country\")\n",
    "#Get a vector for individual words\n",
    "#print(doc[0].vector) #vector for 'Canada', the first word in the text \n",
    "print(mydoc.vector) #Averaged vector for the entire sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- What happens when I give a sentence with strange words (and stop words), and try to get its word vector in Spacy?\n",
    "- Well, at least, this is better than throwing an exception!\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T11:48:15.507141Z",
     "start_time": "2021-04-03T11:48:15.489118Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Q-8wrQlLoPol",
    "outputId": "86297e83-a7a9-41a4-80b7-47eb392a4e66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24652115, -0.00370538,  0.47585845, -0.53857994, -0.10164852,\n",
       "        0.08054233, -0.78846335,  0.57725704,  0.36892247, -0.20525366,\n",
       "        0.49322945, -0.06111569, -1.041065  ,  0.65225863,  0.45910472,\n",
       "        0.3026195 ,  0.4009441 , -0.21229711,  0.4503184 , -0.34189436,\n",
       "        0.3360495 , -0.49880746, -0.67977595,  1.0171478 , -0.85278463,\n",
       "        0.22901264, -0.27532893,  0.8168068 ,  0.21267067,  0.9669028 ,\n",
       "       -0.8624253 , -0.35919917,  0.21813078,  0.4975592 , -0.98805666,\n",
       "        1.1876267 , -1.0230168 , -0.28025502, -0.7530157 ,  1.0236799 ,\n",
       "       -0.4719799 , -0.28097963, -1.1994808 , -1.1338023 , -0.30421656,\n",
       "        0.16297932, -0.05472174,  1.0285486 ,  0.6075866 ,  0.43900877,\n",
       "        1.018733  ,  0.28485686, -0.13497996,  0.23243935,  0.37535557,\n",
       "       -0.19549476, -0.03630176, -0.6209484 ,  0.4153436 , -0.47523615,\n",
       "       -1.0024692 ,  0.84635615, -0.9490654 , -0.6589898 , -0.48663056,\n",
       "       -0.8837726 ,  0.9758252 ,  2.8941932 ,  0.19651982, -0.73825043,\n",
       "        0.5269749 ,  0.40635943, -0.38925475, -0.85894024, -0.2558852 ,\n",
       "        0.24157187,  0.37301666,  0.36961424, -0.310126  , -0.6762302 ,\n",
       "       -0.15953022, -0.81942177,  0.28127828,  0.13779792,  0.7665142 ,\n",
       "       -1.8669608 , -0.90405655, -0.95050293,  0.0399134 , -0.1557334 ,\n",
       "        0.02363989, -0.11876527,  1.7307562 ,  1.4487383 ,  0.07483438,\n",
       "       -1.5223721 ], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = nlp('practicalnlp is a newword')\n",
    "temp[0].vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://github.com/practical-nlp/practical-nlp/blob/master/Ch3/05_Pre_Trained_Word_Embeddings.ipynb\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pre_Trained_Word_Embeddings.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
