{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What? Movie genres classification with KERAS\n",
    "\n",
    "NLTK is a standard python library for natural language processing and computational linguistics.\n",
    "\n",
    "Reference: https://www.mygreatlearning.com/blog/nltk-tutorial-with-python/?highlight=nlp\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical \n",
    "from keras import models \n",
    "from keras import layers \n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dataset and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=10000) \n",
    "dt = np.concatenate((train_data, test_data), axis=0) \n",
    "tar = np.concatenate((train_target, test_target), axis=0) \n",
    "\n",
    "# Train and test dataset\n",
    "dt = convert(dt) \n",
    "tar = np.array(tar).astype(\"float32\")\n",
    "test_x = dt[:9000] \n",
    "test_y = tar[:9000] \n",
    "train_x = dt[9000:] \n",
    "train_y = tar[9000:]\n",
    "model = models.Sequential() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(sequences, dimension = 10000):\n",
    "    \"\"\"\n",
    "    Convert the words into vectors for processing.\n",
    "    For the sake of simplicity, we use the first 10,000 records. \n",
    "    You are free to explore with more data. The execution time \n",
    "    increases with more data.\n",
    "    \"\"\"\n",
    "    results = np.zeros((len(sequences), dimension))  \n",
    "    for i, sequence in enumerate(sequences):   \n",
    "        results[i, sequence] = 1  \n",
    "    return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                500050    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 505,201\n",
      "Trainable params: 505,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input - Layer \n",
    "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
    "# Hidden - Layers \n",
    "model.add(layers.Dropout(0.4, noise_shape=None, seed=None)) \n",
    "model.add(layers.Dense(50, activation = \"relu\")) \n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None)) \n",
    "model.add(layers.Dense(50, activation = \"relu\")) \n",
    "# Output- Layer \n",
    "model.add(layers.Dense(1, activation = \"sigmoid\")) \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "82/82 [==============================] - 3s 38ms/step - loss: 0.4363 - accuracy: 0.7976 - val_loss: 0.2600 - val_accuracy: 0.8938\n",
      "Epoch 2/2\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 0.2292 - accuracy: 0.9120 - val_loss: 0.2599 - val_accuracy: 0.8931\n",
      "Test-Accuracy: 0.8934444487094879\n"
     ]
    }
   ],
   "source": [
    "# compiling the model   \n",
    "model.compile(  optimizer = \"adam\",  loss = \"binary_crossentropy\",  metrics = [\"accuracy\"] ) \n",
    "#The output we are getting is a sparse matrix with the probability of genres most suited are returned as 1.\n",
    "results = model.fit(  train_x, train_y,  epochs= 2,  batch_size = 500,  validation_data = (test_x, test_y) ) \n",
    "\n",
    "print(\"Test-Accuracy:\", np.mean(results.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
